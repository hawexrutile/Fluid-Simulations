{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import base64\n",
    "import imageio\n",
    "import cProfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "from matplotlib.patches import Wedge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Parameters & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# path = r\"Runs/\"\n",
    "# folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "# latest_folder = max(folders, key=lambda f: os.path.getctime(os.path.join(path, f)))\n",
    "\n",
    "# path = os.path.join(path, latest_folder+\"/\")\n",
    "# print(path)\n",
    "path=r\"Runs\\Low Density\\DualRun\\D0.7Run\\Mon_Feb_12_14_11_11_2024/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "def save_param(path):\n",
    "    csv_file_path=path+\"/params.csv\"\n",
    "    # Open the CSV file\n",
    "    with open(csv_file_path, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        mydict = {rows[0]:rows[1] for rows in reader}\n",
    "    return mydict\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path+'/particle_positions.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "variable_dict=save_param(path)\n",
    "\n",
    "r=float(variable_dict[\"sigma\"])/2.0\n",
    "numParticles=int(variable_dict[\"numParticles\"])\n",
    "boxSize=float(variable_dict[\"boxSize\"])\n",
    "timestep=float(variable_dict[\"timestep\"])\n",
    "dataCompression=int(variable_dict[\"dataCompression\"])\n",
    "theta=(float(variable_dict[\"theta\"])) \n",
    "\n",
    "data = load_data(path)\n",
    "particleData = np.array(data)\n",
    "\n",
    "# Find indices and Extract particles with particle ID 1.0\n",
    "indices = np.where(particleData[:, :, 0] == 1.0)\n",
    "particleData1 = particleData[indices[0], indices[1]]\n",
    "particleData1 = particleData1.reshape((particleData.shape[0], -1, particleData.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Image Convention Negator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def min_image_convention(dx, box_size):\n",
    "    \"\"\"\n",
    "    Apply the minimum image convention to get the shortest distance between two points in a periodic box.\n",
    "\n",
    "    Parameters:\n",
    "    dx (float): The distance between the two points.\n",
    "    box_size (float): The size of the periodic box.\n",
    "\n",
    "    Returns:\n",
    "    float: The shortest distance between the two points after applying the minimum image convention.\n",
    "    \"\"\"\n",
    "    dx -= np.round(dx / box_size) * box_size\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "marker_shapes = {\n",
    "    15: 'o',   # Circle\n",
    "    20: '^',   # Triangle\n",
    "    25: 's',   # Square\n",
    "    30: 'D',   # Diamond\n",
    "    35: 'p',   # Pentagon\n",
    "    40: '*',   # Star\n",
    "    45: 'v',   # Inverted triangle\n",
    "    60: '<',   # Left-pointing triangle\n",
    "    90: '>',   # Right-pointing triangle\n",
    "    }\n",
    "cmap = plt.get_cmap('tab20')  # You can choose a different colormap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "def energy_plotly_plotter(xlabel, ylabel):\n",
    "    size=particleData.shape[0]\n",
    "    legend_names = [\"Kinetic Energy\", \"Potential Energy\", \"Total Energy\"]\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    energies=[0,0,0]\n",
    "\n",
    "    # Calculate  kinetic, potential and total energy per particle for each time step\n",
    "    energies[0] = np.average(0.5 * np.sum( particleData[:, :, 4:6] ** 2, axis=2), axis=1)\n",
    "    energies[1] = particleData[:,-1, -1]  #last particle last column contains the avergae PE per particle for that timestep\n",
    "    energies[2] = energies[0] + energies[1]\n",
    "\n",
    "    # Create Plotly figure\n",
    "    fig = go.Figure()\n",
    "    time = [i*dataCompression*timestep for i in range(size-1)]\n",
    "    for i in range(3): fig.add_trace(go.Scatter(x=time, y=energies[i], mode='lines', name=legend_names[i], line=dict(color=colors[i])))\n",
    "\n",
    "    fig.update_layout(title=\"Energy Plot\", xaxis_title=xlabel, yaxis_title=ylabel, width=1200, height=600)\n",
    "    pio.write_html(fig, path+'/tempi.html')\n",
    "    fig.show()\n",
    "\n",
    "energy_plotly_plotter(\"Time\", \"Energy per Particle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Frame Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "def FinalSysImagePlotter(particle_data, box_size, path, theta):\n",
    "    # Create a figure and axis for the Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, box_size)\n",
    "    ax.set_ylim(0, box_size)\n",
    "    color=[\"red\", \"black\"]\n",
    "    for id, _, x, y, _, _, _, _ in particle_data[-1]:\n",
    "        circle = plt.Circle((x, y), radius=r, linewidth=0)\n",
    "        #color of the circle is based on the id of the particle\n",
    "        circle.set_facecolor(color[int(id-2)])\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    plt.xlabel('X-coordinate')\n",
    "    plt.ylabel('Y-coordinate')\n",
    "    #add theta value in the title\n",
    "    plt.title('Final Image of System, Theta = ' + str(theta))\n",
    "    \n",
    "    # Save and show the snapshot\n",
    "    plt.savefig(path + \"/FinalFrame.png\") \n",
    "    plt.show()\n",
    "\n",
    "# Plots the final system image\n",
    "FinalSysImagePlotter(particleData1, boxSize, path, theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def generate_frames_parallel(skipped_particle_data, frame, box_size, theta, path, time_step, data_compression, skip):\n",
    "    plt.figure()\n",
    "    plt.xlim(0, box_size)\n",
    "    plt.ylim(0, box_size)\n",
    "    frame_path = os.path.join(path, f'/frame_{frame}.png')\n",
    "\n",
    "    # Plot the particles at the given frame as circles\n",
    "    for id, _, x, y, _, _, _, _ in skipped_particle_data[frame]:\n",
    "        color=[\"red\", \"black\"]\n",
    "        circle = plt.Circle((x, y), radius=r, linewidth=0)\n",
    "        circle.set_facecolor(color[int(id)-2])\n",
    "        plt.gca().add_patch(circle)\n",
    "    # Add the timestep to the plot\n",
    "    time = math.floor(frame * data_compression * time_step * skip)\n",
    "    \n",
    "    plt.text(0.05, 0.95, f'Time: {time}', transform=plt.gca().transAxes, fontsize=10, verticalalignment='top')\n",
    "    plt.title(f\"\\u03B8={round(theta)}\\u00B0\")\n",
    "    frame_plt = plt\n",
    "    frame_plt.savefig(frame_path)\n",
    "    plt.close()\n",
    "\n",
    "def show_gif(fname):\n",
    "    with open(fname, 'rb') as fd:\n",
    "        b64 = base64.b64encode(fd.read()).decode('ascii')\n",
    "\n",
    "    gif_html = f'<img src=\"data:image/gif;base64,{b64}\" />'\n",
    "    link_html = f'<a href=\"{fname}\" target=\"_blank\">Click here for the GIF</a>'\n",
    "\n",
    "    return display.HTML(f'{gif_html}<br>{link_html}')\n",
    "\n",
    "def animator(particle_data, box_size, theta, path, time_step, data_compression, skip):\n",
    "    skipped_particle_data = particle_data[::skip]\n",
    "    num_frames = skipped_particle_data.shape[0]\n",
    "    # Use joblib for parallel execution\n",
    "    Parallel(n_jobs=-1)(delayed(generate_frames_parallel)(skipped_particle_data, frame, box_size, theta, path, time_step, data_compression, skip) for frame in tqdm(range(num_frames)))\n",
    "\n",
    "    # Combine frames into a GIF using imageio\n",
    "    with imageio.get_writer(path+'/animation.gif', duration=0.1) as writer:\n",
    "        for frame in range(num_frames):\n",
    "            frame_path = os.path.join(path, f'/frame_{frame}.png')\n",
    "            image = imageio.imread(frame_path)\n",
    "            writer.append_data(image)\n",
    "            \n",
    "    # Delete individual PNG files\n",
    "    for frame in range(num_frames):\n",
    "        frame_path = os.path.join(path, f'/frame_{frame}.png')\n",
    "        os.remove(frame_path)\n",
    "    \n",
    "# animator(particleData, boxSize, theta, path, timestep, dataCompression, 10)\n",
    "# show_gif(path+'/animation.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = len(particleData)\n",
    "def update(frame, box_size):\n",
    "    # ?Function to update each frame\n",
    "    plt.figure()\n",
    "    plt.xlim(0, box_size)\n",
    "    plt.ylim(0, box_size)\n",
    "\n",
    "    positions = particleData[frame, :, :]\n",
    "    corner_positions=positions[[0,-1, 9, -10, 73],:]\n",
    "    # Plot the particles at the given frame as circles\n",
    "    try:\n",
    "        for x, y, _, _, phi, _ in particleData[frame]:\n",
    "            circle = plt.Circle((x, y), radius=r, linewidth=0)\n",
    "            # add an if statement to change the color for the last particle in the list\n",
    "            sector = Wedge((x, y), 6, np.degrees(phi) - theta, np.degrees(phi) + theta, ec='black')\n",
    "            plt.gca().add_patch(sector)\n",
    "            plt.gca().add_patch(circle)\n",
    "        for x, y, vx, vy, phi, _ in corner_positions:\n",
    "            sector = Wedge((x, y), 6, np.degrees(phi) - theta, np.degrees(phi) + theta, ec='black', fc='red')\n",
    "            plt.gca().add_patch(sector)\n",
    "    except:\n",
    "        plt.gca().set_facecolor('black')  # Add this line to make the background black\n",
    "    return plt\n",
    "\n",
    "def generate_frames_parallel(frame, box_size):\n",
    "    frame_plt = update(frame, box_size)\n",
    "    frame_path = os.path.join(path, f'frame_{frame}.png')\n",
    "    frame_plt.savefig(frame_path)\n",
    "    plt.close()\n",
    "\n",
    "# Use joblib for parallel execution\n",
    "Parallel(n_jobs=-1)(delayed(generate_frames_parallel)(frame, boxSize) for frame in tqdm(range(num_frames)))\n",
    "\n",
    "# ?Combine frames into a GIF using imageio\n",
    "with imageio.get_writer(path+'animation.gif', duration=0.1) as writer:\n",
    "    for frame in range(num_frames):\n",
    "        frame_path = os.path.join(path, f'frame_{frame}.png')\n",
    "        image = imageio.imread(frame_path)\n",
    "        writer.append_data(image)\n",
    "    \n",
    "\n",
    "# ?Delete individual PNG files\n",
    "for frame in range(num_frames):\n",
    "    frame_path = os.path.join(path, f'frame_{frame}.png')\n",
    "    os.remove(frame_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = particleData[:1000, :, -2]\n",
    "dphi = np.diff(phi, axis=0)\n",
    "print (dphi.shape)\n",
    "average_phi = np.average(np.abs(dphi), axis=0)\n",
    "# print the position of the minimum value of average phi\n",
    "print(np.argmin(average_phi))\n",
    "# plot the average phi\n",
    "plt.plot(average_phi)\n",
    "plt.xlabel('Particles')\n",
    "plt.ylabel('Average Orientation deviation')\n",
    "plt.title('Average Orientation deviation vs particles')\n",
    "plt.savefig(path + \"/AveragePhi.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def MSD_particle(i, positions, box_size, size):\n",
    "    n = np.zeros((size - 1, 2))\n",
    "    result = []\n",
    "    for j in range(math.floor(size - 1.0)):\n",
    "        d = positions[j + 1:, i] - positions[:-j - 1, i]\n",
    "        d -= np.round((d - n) / (box_size)) * box_size\n",
    "        n = d[:-1]\n",
    "        result.append(np.mean((np.linalg.norm(d, axis=1))**2))\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def MSD(particle_data, box_size, time_step, data_compression, skip):\n",
    "    positions = particle_data[::skip, :, 2:4]\n",
    "    size=positions.shape[0]\n",
    "    num_particles=positions.shape[1]\n",
    "    MSDPerParticle = np.zeros((num_particles, size - 1))\n",
    "\n",
    "    # Create a nested for-loop running through each particle and all possible gap values to create the MSD Matrix\n",
    "    MSDPerParticle=Parallel(n_jobs=-1)(delayed(MSD_particle)(i, positions, box_size, size) for i in tqdm(range(num_particles)))\n",
    "    MSDPerParticle = np.array(MSDPerParticle)\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the MSD values\n",
    "    averageMSDPerGap=[np.mean(MSDPerParticle[:, j]) for j in range(size-1)]\n",
    "    stdMSDPerGap=[np.std(MSDPerParticle[:, j]) for j in range(size-1)]\n",
    "\n",
    "    x=[i*data_compression*time_step*skip for i in range(math.floor(size-1.0))]\n",
    "    y=averageMSDPerGap[:len(x)]\n",
    "    dy=stdMSDPerGap[:len(x)]\n",
    "    return x, y, dy\n",
    "# x,y,dy=MSD(particleData1, boxSize, timestep, dataCompression, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def plot_MSD(x,y, theta, path):\n",
    "    color = cmap(theta/90)  # Use theta to get a unique color from the colormap\n",
    "    theta_marker = marker_shapes.get(round(theta), 'o')  # Default to circle if theta not in the dictionary\n",
    "    #fit and plot the data with an exponential function and print the fit values\n",
    "    def func(v, b):\n",
    "        return 4*b * np.array(v)\n",
    "    popt, pcov = curve_fit(func, x, y, p0=[100])\n",
    "    plt.plot(x, func(x, *popt), label=f'Fit:'\" D_t=\"+str(round(popt[0], 2)), color=color)\n",
    "    print (popt)\n",
    "    \n",
    "    # plt.plot(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0', marker='o', color=color, markersize=1)\n",
    "    plt.scatter(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0', marker=theta_marker, color=color, s=2)\n",
    "    # plt.yscale('log')\n",
    "    # plt.xscale('log')\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Time Gap\")\n",
    "    plt.ylabel(\"MSD\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=7)\n",
    "    plt.title(\"Mean Squared Displacement\")\n",
    "    plt.tight_layout()\n",
    "    # Set the figure size (adjust these values as needed)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 6)\n",
    "    plt.savefig(path+\"/MSD.png\", bbox_inches = 'tight')\n",
    "    # return popt and theta as a dictionary for simm plot\n",
    "    return popt\n",
    "\n",
    "# plot_MSD(x,y, theta, path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Correlation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def autoCorrelation_particle(i, positions, box_size, size):\n",
    "    #for each particle i calculate min_image_convention(positions[1:size, i] - positions[0:size-1, i], b)\n",
    "    direction_vector=min_image_convention(positions[1:, i] - positions[0:-1, i], box_size)\n",
    "    dvnorm = np.linalg.norm(direction_vector, axis=1)\n",
    "    direction_vector = direction_vector/dvnorm[:, np.newaxis]\n",
    "    result = []\n",
    "    # Create a nested for-loop running through each particle and gap values\n",
    "    for j in range(size - 1):\n",
    "        result.append(0)\n",
    "        # data[k + 1][i] - data[k][i]\n",
    "        d1 = direction_vector[0:-j-2]\n",
    "        # data[k + j + 2][i] - data[k + j + 1][i]\n",
    "        d2 = direction_vector[j:-2]\n",
    "\n",
    "        dot_product = np.sum(d1 * d2, axis=1)\n",
    "        result[j] = np.sum(dot_product) / (size - j - 1)\n",
    "    return result\n",
    "def autoCorrelation(particle_data, box_size, data_compression, time_step, skip):\n",
    "    # Extracting x and y coordinates from the array\n",
    "    positions = particle_data[::skip, :, 2:4]\n",
    "    size=positions.shape[0]\n",
    "    num_particles=positions.shape[1]\n",
    "    # Create an empty list to store the \"autoCorrelation list\".\n",
    "    autoCorrelationPerParticle = np.zeros((num_particles, size - 1))\n",
    "\n",
    "    # Create a nested for-loop running through each particle and gap values\n",
    "    autoCorrelationPerParticle = np.zeros((num_particles, size))\n",
    "    autoCorrelationPerParticle=Parallel(n_jobs=-1)(delayed(autoCorrelation_particle)(i, positions, box_size, size) for i in tqdm(range(num_particles)))\n",
    "    autoCorrelationPerParticle = np.array(autoCorrelationPerParticle)\n",
    "    \n",
    "    averageAutoCorrelationPerGap=[np.mean(autoCorrelationPerParticle[:, j]) for j in range(size-1)]\n",
    "    stdAutoCorrelationPerGap=[np.std(autoCorrelationPerParticle[:, j]) for j in range(size-1)]\n",
    "\n",
    "    x=[i*data_compression*time_step*skip for i in range(math.floor(size-2))]\n",
    "    y=averageAutoCorrelationPerGap[:len(x)]\n",
    "    dy=stdAutoCorrelationPerGap[:len(x)]\n",
    "    return x, y, dy\n",
    "\n",
    "# x, y, dy=autoCorrelation(particleData1, boxSize, dataCompression, timestep, 1)\n",
    "#NOTE - Maybe plot sina*sinb+cosa*cosb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def plot_AutoCorrelation(x,y, dy, theta, path):\n",
    "    # fit the curve with a sinusoidal decaying exponential\n",
    "    def func(v, b, c, d):\n",
    "        return  np.cos(2*math.pi*np.array(v)/b) * np.exp( -(np.array(v)**c)/d**c)\n",
    "    try: popt, pcov = curve_fit(func, x, y, p0=[100, 1.0,100])\n",
    "    except: popt=[0,0,0]\n",
    "\n",
    "    # plt.plot(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0')\n",
    "    plt.errorbar(x,y, yerr=dy, ecolor = 'lightblue', capsize=0)\n",
    "    plt.plot(x, func (x, *popt), label=f'Fit:' \" t_cos=\"+str(round(popt[0], 2)) + \", \\u03B2=\"+str(round(popt[1], 2)) + \", t_exp=\"+str(round(popt[2], 2)), color='red')\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Time Gap\")\n",
    "    plt.ylabel(\"Auto-Correlation\")\n",
    "    plt.title(f\"Auto-Correlation at \\u03B8={round(theta)}\\u00B0\")\n",
    "    # Add the fitting equation to the plot\n",
    "    equation = f'Fit: cos(2\\u03C0t / t_cos) * exp( -(v^\\u03B2) / t_exp)'\n",
    "    plt.text(0.05, 0.95, equation, transform=plt.gca().transAxes, fontsize=10, verticalalignment='top')\n",
    "    plt.legend()\n",
    "\n",
    "    # Set the figure size (adjust these values as needed)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 6)\n",
    "    plt.savefig(path+\"/autoCorrelation.png\", bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# plot_AutoCorrelation(x,y, dy, theta, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def persistence_particle(i, positions, box_size, size):\n",
    "    #for each particle i calculate min_image_convention(positions[1:size, i] - positions[0:size-1, i], b)\n",
    "    direction_vector=min_image_convention(positions[1:, i] - positions[0:-1, i], box_size)\n",
    "    dvnorm = np.linalg.norm(direction_vector, axis=1)\n",
    "    direction_vector = direction_vector/dvnorm[:, np.newaxis]\n",
    "    cosine_matrix = np.dot(direction_vector, direction_vector.T)\n",
    "    result = []\n",
    "    # Create a nested for-loop running through each particle and gap values\n",
    "    for j in range(size):\n",
    "        result.append(0)\n",
    "        for k in range(size - j - 2):\n",
    "            cosines = cosine_matrix[k,k:k+j+1]                 #Broadcasting of numpy arrays is the reason we can do the next step\n",
    "            flag = np.any(cosines < 0)\n",
    "            if not flag: result[j] += 1.0\n",
    "        result[j] = result[j]/ int(size - j)\n",
    "    return result\n",
    "\n",
    "def persistence(particle_data, box_size, data_compression, time_step, skip):\n",
    "    # Extracting x and y coordinates from the array\n",
    "    positions = particle_data[::skip, :, 2:4]\n",
    "    size=positions.shape[0]\n",
    "    num_particles=positions.shape[1]\n",
    "    \n",
    "    persistencePerParticle = np.zeros((num_particles, size))\n",
    "    persistencePerParticle=Parallel(n_jobs=-1)(delayed(persistence_particle)(i, positions, box_size, size) for i in tqdm(range(num_particles)))\n",
    "    persistencePerParticle = np.array(persistencePerParticle)\n",
    "    # Create a for loop running through persistencePerParticle[i] and finding the mean persistence\n",
    "    averagePersistencePerGap=[np.mean(persistencePerParticle[:, j]) for j in range(size)]\n",
    "\n",
    "    x = [i*data_compression*time_step*skip for i in range(size-1)]\n",
    "    y = averagePersistencePerGap[:len(x)]\n",
    "    \n",
    "    return x, y\n",
    "# x, y=persistence(particleData1, boxSize, dataCompression, timestep, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def plot_persistence(x, y, theta, save_path):\n",
    "    color = cmap(theta/90)  # Use theta to get a unique color from the colormap\n",
    "    theta_marker = marker_shapes.get(round(theta), 'o')  # Default to circle if theta not in the dictionary\n",
    "    #fit and plot the data with an exponential function and print the fit values\n",
    "    def func(v, a, b, c):\n",
    "        # return a * np.exp(-np.array(v)/b)\n",
    "        return a * np.exp(-((np.array(v))**c)/b)\n",
    "    popt, pcov = curve_fit(func, x, y, p0=[1, 100, 1])\n",
    "    plt.plot(x, func(x, *popt), label=f'Fit:'\" a=\"+str(round(popt[0], 2))+\" b=\"+str(round(popt[1], 2))+\" c=\"+str(round(popt[2], 2)), color=color)\n",
    "    # print (popt)\n",
    "\n",
    "    # plt.plot(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0', marker=theta_marker, color=color, markersize=2)\n",
    "    plt.scatter(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0', marker=theta_marker, color=color, s=2)\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    # plt.yscale('log', base=2)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Time Gap\")\n",
    "    plt.ylabel(\"Persistence\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=7)\n",
    "    # Set the figure size (adjust these values as needed)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 6)\n",
    "    plt.savefig(save_path+\"/persistence.png\", bbox_inches = 'tight')\n",
    "    # return popt\n",
    "# plot_persistence(x, y, theta, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence(datain):\n",
    "    data=datain\n",
    "    size=particleData.shape[0]\n",
    "    # Create an empty list to store the \"Persistence list\" and  average persistence per gap\n",
    "    persistencePerParticle = [[0.0] * (size) for i in range(numParticles)]\n",
    "    averagePersistencePerGap = [0.0] * (size)\n",
    "    # Create a nested for-loop running through each particle all the possible gap values to create the Persistence Matrix; here j will be called \"gap\"\n",
    "    for i in tqdm(range(numParticles)):\n",
    "        for j in range(size):\n",
    "            for k in range(size - j - 1):  # -1 because we want to avoid the last particle as there is no k+1 for it\n",
    "                flag = 0\n",
    "                d1x = min_image_convention(data[k + 1][i][0] - data[k][i][0], boxSize)\n",
    "                d1y = min_image_convention(data[k + 1][i][1] - data[k][i][1], boxSize)\n",
    "                d1norm = math.sqrt(d1x**2 + d1y**2)\n",
    "                for l in range(j + 1):\n",
    "                    d2x = min_image_convention(data[k + l + 1][i][0] - data[k + l][i][0], boxSize)\n",
    "                    d2y = min_image_convention(data[k + l + 1][i][1] - data[k + l][i][1], boxSize)\n",
    "                    d2norm = math.sqrt(d2x**2 + d2y**2)\n",
    "                    if (d1x * d2x + d1y * d2y) / (d1norm * d2norm) < 0:  # if cos becomes negative\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    persistencePerParticle[i][j] += 1.0\n",
    "\n",
    "            persistencePerParticle[i][j] /= int(size - j)\n",
    "\n",
    "    # Create a for loop running through persistencePerParticle[i] and finding the mean persistence\n",
    "    for j in tqdm(range(size)):\n",
    "        persistenceValues = []\n",
    "        for i in range(numParticles):\n",
    "            # Add the persistence of each particle at a given gap to the list\n",
    "            persistenceValues.append(persistencePerParticle[i][j])\n",
    "\n",
    "        # Calculate the mean  of the persistence values\n",
    "        averagePersistencePerGap[j] = np.mean(persistenceValues)\n",
    "\n",
    "    x = [i*dataCompression*timestep for i in range(size-1)]\n",
    "    y = averagePersistencePerGap[:len(x)]\n",
    "    \n",
    "    return y, x\n",
    "x, y=persistence(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentFolder = r\"Runs\\Low Density\\DualRunPassive\\D0.5Run\" \n",
    "filePaths = [f.path+\"/\" for f in os.scandir(parentFolder) if f.is_dir()]\n",
    "MSDp=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sim Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simGif():\n",
    "    for file_path in tqdm(filePaths):\n",
    "        data = load_data(file_path)\n",
    "        particleData = np.array(data)\n",
    "        \n",
    "        variable_dict=save_param(file_path)\n",
    "        theta=(float(variable_dict[\"theta\"]))\n",
    "        boxSize=float(variable_dict[\"boxSize\"])\n",
    "        timestep=float(variable_dict[\"timestep\"])\n",
    "        dataCompression=int(variable_dict[\"dataCompression\"])\n",
    "        FinalSysImagePlotter(particleData, boxSize, file_path, theta)\n",
    "        # animator(particleData, boxSize, theta, file_path, timestep, dataCompression, 5)\n",
    "simGif()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sim Autocorelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simAutoC():\n",
    "    for file_path in tqdm(filePaths):\n",
    "        data = load_data(file_path)\n",
    "        particleData = np.array(data)\n",
    "        \n",
    "        variable_dict=save_param(file_path)\n",
    "        theta=(float(variable_dict[\"theta\"]))\n",
    "        boxSize=float(variable_dict[\"boxSize\"])\n",
    "        timestep=float(variable_dict[\"timestep\"])\n",
    "        dataCompression=int(variable_dict[\"dataCompression\"])\n",
    "        out=autoCorrelation(particleData, boxSize, dataCompression, timestep, 1)\n",
    "        plot_AutoCorrelation(out[0],out[1], out[2], theta, file_path)\n",
    "        \n",
    "simAutoC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simultaneous Averaging Plots (MSD & Persistence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simPlot(filePaths):\n",
    "    Plot_Data={}\n",
    "    Data_List={}\n",
    "    for file_path in tqdm(filePaths):\n",
    "        data = load_data(file_path)\n",
    "        particle_data = np.array(data)\n",
    "        indices = np.where(particle_data[:, :, 0] == 1.0)\n",
    "        particle_data1 = particle_data[indices[0], indices[1]]\n",
    "        particle_data1 = particle_data1.reshape((particle_data.shape[0], -1, particle_data.shape[2]))\n",
    "        \n",
    "        variable_dict=save_param(file_path)\n",
    "        theta=(float(variable_dict[\"theta\"]))\n",
    "        boxSize=float(variable_dict[\"boxSize\"])\n",
    "        timestep=float(variable_dict[\"timestep\"])\n",
    "        dataCompression=int(variable_dict[\"dataCompression\"])\n",
    "        \n",
    "        if MSDp: a = np.array(MSD(particle_data1, boxSize, timestep, dataCompression, 1))\n",
    "        else: a = np.array(persistence(particle_data1, boxSize, dataCompression, timestep, 2))\n",
    "        \n",
    "        if theta not in Data_List: Data_List[theta] = [a]\n",
    "        else: Data_List[theta].append(a)\n",
    "    for theta in Data_List:\n",
    "        Plot_Data[theta] = [Data_List[theta][0][0], np.mean(Data_List[theta], axis=0)[1]]\n",
    "    No_of_Runs_per_theta = {key: len(value) for key, value in Data_List.items()}\n",
    "    print (No_of_Runs_per_theta)\n",
    "    return Plot_Data, Data_List\n",
    "lists=simPlot(filePaths)\n",
    "l = dict(sorted(lists[0].items()))\n",
    "d = dict(sorted(lists[1].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_values={}\n",
    "for theta in l:\n",
    "        #For each data e store the fir vlues in a dictionary\n",
    "        fit_values[theta] = []\n",
    "        def func(v, a, b, c):\n",
    "                if MSDp: fu = 4*b*np.array(v)\n",
    "                else: fu = a*np.exp(-((np.array(v))**c)/b)\n",
    "                return fu\n",
    "        for entry in d[theta]:\n",
    "                x = entry[0]\n",
    "                y = entry[1]\n",
    "                try: popt, pcov = curve_fit(func, x[1:], y[1:], p0=[1, 100, 1])\n",
    "                except: popt = [0,0,0]\n",
    "                fit_values[theta].append(popt[1])\n",
    "        if MSDp:plot_MSD(l[theta][0], l[theta][1], theta, parentFolder)\n",
    "        else: plot_persistence(l[theta][0][1:], l[theta][1][1:], theta, parentFolder)\n",
    "        \n",
    "# Save to Excel\n",
    "df = pd.DataFrame.from_dict(fit_values)\n",
    "if MSDp: df.to_excel(parentFolder+\"/fit_valuesMSD.xlsx\")\n",
    "else: df.to_excel(parentFolder+\"/fit_valuesPersistence.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of the plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Read from Excel and save it as a dictionary\n",
    "if MSDp: df = pd.read_excel(parentFolder+\"/fit_valuesMSD.xlsx\")\n",
    "else: df = pd.read_excel(parentFolder+\"/fit_valuesPersistence.xlsx\")\n",
    "fit_values = df.set_index('Unnamed: 0').to_dict('list')\n",
    "\n",
    "# Plot the fit values by averaging the fit values for each theta also plot the standard deviation\n",
    "x = list(fit_values.keys())\n",
    "y = [np.mean(fit_values[theta]) for theta in x]\n",
    "dy = [np.std(fit_values[theta]) for theta in x]\n",
    "plt.plot(x, y, color='black', linestyle='-', marker='o')\n",
    "plt.errorbar(x, y, yerr=dy, fmt='o', color='black', ecolor='RED', elinewidth=2, capsize=2)\n",
    "plt.xlabel('Vission Angle \\u03B8')\n",
    "if MSDp: \n",
    "    plt.ylabel('Diffusion Coefficient')\n",
    "    plt.title('Diffusion Coefficient vs Vission Angle')\n",
    "    plt.savefig(parentFolder+\"/MSDfit_values.png\")\n",
    "else: \n",
    "    plt.ylabel('Persistence Coefficient')\n",
    "    plt.savefig(parentFolder+\"/Persistencefit_values.png\")\n",
    "\n",
    "# \n",
    "plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of the plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "gparentFolder = r\"Runs\\Low Density\\DualRunPassive\"\n",
    "filePaths = [f.path+\"/\" for f in os.scandir(gparentFolder) if f.is_dir()]\n",
    "\n",
    "# Define the colors for each plot\n",
    "colors = ['green', 'red', 'blue']\n",
    "ratios=[\"625:625\", \"625:268\", \"625:70\"]\n",
    "\n",
    "# Loop over each file path\n",
    "for file_path, color, ratio in zip(filePaths, colors, ratios):\n",
    "    # Read from Excel and save it as a dictionary\n",
    "    if MSDp: df = pd.read_excel(file_path+\"/fit_valuesMSD.xlsx\")\n",
    "    else: df = pd.read_excel(file_path+\"/fit_valuesPersistence.xlsx\")\n",
    "    fit_values = df.set_index('Unnamed: 0').to_dict('list')\n",
    "\n",
    "    # Plot the fit values by averaging the fit values for each theta also plot the standard deviation\n",
    "    x = list(fit_values.keys())\n",
    "    y = [np.mean(fit_values[theta]) for theta in x]\n",
    "    dy = [np.std(fit_values[theta]) for theta in x]\n",
    "    plt.plot(x, y, color=color, linestyle='-', marker='o')\n",
    "    plt.errorbar(x, y, yerr=dy, fmt='o', color=color, label=ratio, ecolor='black', elinewidth=2, capsize=2)\n",
    "    # add legend base on file name and save the plot\n",
    "plt.xlabel('Vission Angle \\u03B8')\n",
    "plt.legend(fontsize=10)\n",
    "if MSDp: \n",
    "    plt.ylabel('Diffussion Coefficient')\n",
    "    plt.savefig(gparentFolder+\"/MSD_fit_values.png\")\n",
    "else: \n",
    "    plt.ylabel('Persistence Coefficient')\n",
    "    plt.savefig(gparentFolder+\"/Persistence_fit_values.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run(\"persistence(data)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
