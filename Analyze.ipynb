{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import base64\n",
    "import imageio\n",
    "import cProfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "from matplotlib.patches import Wedge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Parameters & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# path = \"Runs/\"\n",
    "# folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "# latest_folder = max(folders, key=lambda f: os.path.getctime(os.path.join(path, f)))\n",
    "\n",
    "# path = os.path.join(path, latest_folder+\"/\")\n",
    "# print(path)\n",
    "path=r\"Runs\\High Density\\CRun\\Thu_Jan_18_23_47_35_2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "def save_param(path):\n",
    "    csv_file_path=path+\"/params.csv\"\n",
    "    # Open the CSV file\n",
    "    with open(csv_file_path, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        mydict = {rows[0]:rows[1] for rows in reader}\n",
    "    return mydict\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path+'/particle_positions.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "variable_dict=save_param(path)\n",
    "\n",
    "r=float(variable_dict[\"sigma\"])/2.0\n",
    "numParticles=int(variable_dict[\"numParticles\"])\n",
    "boxSize=float(variable_dict[\"boxSize\"])\n",
    "timestep=float(variable_dict[\"timestep\"])\n",
    "dataCompression=int(variable_dict[\"dataCompression\"])\n",
    "theta=(float(variable_dict[\"theta\"])) \n",
    "\n",
    "data = load_data(path)\n",
    "particleData = np.array(data)\n",
    "\n",
    "print(variable_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Image Convention Negator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_image_convention(dx, box_size):\n",
    "    # Apply minimum image convention to get the shortest distance\n",
    "    dx -= np.round(dx / box_size) * box_size\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_shapes = {\n",
    "    15: 'o',   # Circle\n",
    "    20: '^',   # Triangle\n",
    "    25: 's',   # Square\n",
    "    30: 'D',   # Diamond\n",
    "    35: 'p',   # Pentagon\n",
    "    40: '*',   # Star\n",
    "    45: 'v',   # Inverted triangle\n",
    "    60: '<',   # Left-pointing triangle\n",
    "    90: '>',   # Right-pointing triangle\n",
    "    }\n",
    "cmap = plt.get_cmap('tab20')  # You can choose a different colormap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "def energy_plotly_plotter(xlabel, ylabel):\n",
    "    size=particleData.shape[0]\n",
    "    legend_names = [\"Kinetic Energy\", \"Potential Energy\", \"Total Energy\"]\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    energies=[0,0,0]\n",
    "\n",
    "    # Calculate  kinetic, potential and total energy per particle for each time step\n",
    "    energies[0] = np.average(0.5 * np.sum( particleData[:, :, 2:4] ** 2, axis=2), axis=1)\n",
    "    energies[1] = particleData[:,-1, -1]  #last particle last column contains the avergae PE per particle for that timestep\n",
    "    energies[2] = energies[0] + energies[1]\n",
    "\n",
    "    # Create Plotly figure\n",
    "    fig = go.Figure()\n",
    "    time = [i*dataCompression*timestep for i in range(size-1)]\n",
    "    for i in range(3): fig.add_trace(go.Scatter(x=time, y=energies[i], mode='lines', name=legend_names[i], line=dict(color=colors[i])))\n",
    "\n",
    "    fig.update_layout(title=\"Energy Plot\", xaxis_title=xlabel, yaxis_title=ylabel, width=1200, height=600)\n",
    "    pio.write_html(fig, path+'/tempi.html')\n",
    "    fig.show()\n",
    "\n",
    "energy_plotly_plotter(\"Time\", \"Energy per Particle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Frame Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "def FinalSysImagePlotter(particle_data, box_size):\n",
    "    # Create a figure and axis for the Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, box_size)\n",
    "    ax.set_ylim(0, box_size)\n",
    "    \n",
    "    for x, y, vx, vy, phi, _ in particle_data[-1]:\n",
    "        circle = plt.Circle((x, y), radius=r, linewidth=0)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    plt.xlabel('X-coordinate')\n",
    "    plt.ylabel('Y-coordinate')\n",
    "    plt.title('Final Image of System')\n",
    "    \n",
    "    # Save and show the snapshot\n",
    "    plt.savefig(path + \"/FinalFrame.png\") \n",
    "    plt.show()\n",
    "\n",
    "# Plots the final system image\n",
    "FinalSysImagePlotter(particleData, boxSize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def generate_frames_parallel(skipped_particle_data, frame, box_size, path):\n",
    "    plt.figure()\n",
    "    plt.xlim(0, box_size)\n",
    "    plt.ylim(0, box_size)\n",
    "    frame_path = os.path.join(path, f'/frame_{frame}.png')\n",
    "\n",
    "    # Plot the particles at the given frame as circles\n",
    "    for x, y, _, _, _, _ in skipped_particle_data[frame]:\n",
    "        circle = plt.Circle((x, y), radius=r, linewidth=0)\n",
    "        # add an if statement to change the color for the last particle in the list\n",
    "        plt.gca().add_patch(circle)\n",
    "    frame_plt = plt\n",
    "    frame_plt.savefig(frame_path)\n",
    "    plt.close()\n",
    "\n",
    "def show_gif(fname):\n",
    "    with open(fname, 'rb') as fd:\n",
    "        b64 = base64.b64encode(fd.read()).decode('ascii')\n",
    "\n",
    "    gif_html = f'<img src=\"data:image/gif;base64,{b64}\" />'\n",
    "    link_html = f'<a href=\"{fname}\" target=\"_blank\">Click here for the GIF</a>'\n",
    "\n",
    "    return display.HTML(f'{gif_html}<br>{link_html}')\n",
    "\n",
    "def animator(particle_data, box_size, path, skip):\n",
    "    skipped_particle_data = particle_data[::skip]\n",
    "    num_frames = skipped_particle_data.shape[0]\n",
    "    # Use joblib for parallel execution\n",
    "    Parallel(n_jobs=-1)(delayed(generate_frames_parallel)(skipped_particle_data, frame, box_size, path) for frame in tqdm(range(num_frames)))\n",
    "\n",
    "    # Combine frames into a GIF using imageio\n",
    "    with imageio.get_writer(path+'/animation.gif', duration=0.1) as writer:\n",
    "        for frame in range(num_frames):\n",
    "            frame_path = os.path.join(path, f'/frame_{frame}.png')\n",
    "            image = imageio.imread(frame_path)\n",
    "            writer.append_data(image)\n",
    "            \n",
    "    # Delete individual PNG files\n",
    "    for frame in range(num_frames):\n",
    "        frame_path = os.path.join(path, f'/frame_{frame}.png')\n",
    "        os.remove(frame_path)\n",
    "    show_gif(path+'/animation.gif')\n",
    "animator(particleData, boxSize, path, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = len(particle_data)\n",
    "def update(frame, box_size):\n",
    "    # ?Function to update each frame\n",
    "    plt.figure()\n",
    "    plt.xlim(0, box_size)\n",
    "    plt.ylim(0, box_size)\n",
    "\n",
    "    positions = particle_data[frame, :, :]\n",
    "    corner_positions=positions[[0,-1, 9, -10, 73],:]\n",
    "    # Plot the particles at the given frame as circles\n",
    "    try:\n",
    "        for x, y, _, _, phi, _ in particle_data[frame]:\n",
    "            circle = plt.Circle((x, y), radius=r, linewidth=0)\n",
    "            # add an if statement to change the color for the last particle in the list\n",
    "            sector = Wedge((x, y), 6, np.degrees(phi) - theta, np.degrees(phi) + theta, ec='black')\n",
    "            plt.gca().add_patch(sector)\n",
    "            plt.gca().add_patch(circle)\n",
    "        for x, y, vx, vy, phi, _ in corner_positions:\n",
    "            sector = Wedge((x, y), 6, np.degrees(phi) - theta, np.degrees(phi) + theta, ec='black', fc='red')\n",
    "            plt.gca().add_patch(sector)\n",
    "    except:\n",
    "        plt.gca().set_facecolor('black')  # Add this line to make the background black\n",
    "    return plt\n",
    "\n",
    "def generate_frames_parallel(frame, box_size):\n",
    "    frame_plt = update(frame, box_size)\n",
    "    frame_path = os.path.join(path, f'frame_{frame}.png')\n",
    "    frame_plt.savefig(frame_path)\n",
    "    plt.close()\n",
    "\n",
    "# Use joblib for parallel execution\n",
    "Parallel(n_jobs=-1)(delayed(generate_frames_parallel)(frame, boxSize) for frame in tqdm(range(num_frames)))\n",
    "\n",
    "# ?Combine frames into a GIF using imageio\n",
    "with imageio.get_writer(path+'animation.gif', duration=0.1) as writer:\n",
    "    for frame in range(num_frames):\n",
    "        frame_path = os.path.join(path, f'frame_{frame}.png')\n",
    "        image = imageio.imread(frame_path)\n",
    "        writer.append_data(image)\n",
    "    \n",
    "\n",
    "# ?Delete individual PNG files\n",
    "for frame in range(num_frames):\n",
    "    frame_path = os.path.join(path, f'frame_{frame}.png')\n",
    "    os.remove(frame_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = particleData[:1000, :, -2]\n",
    "dphi = np.diff(phi, axis=0)\n",
    "print (dphi.shape)\n",
    "average_phi = np.average(np.abs(dphi), axis=0)\n",
    "# print the position of the minimum value of average phi\n",
    "print(np.argmin(average_phi))\n",
    "# plot the average phi\n",
    "plt.plot(average_phi)\n",
    "plt.xlabel('Particles')\n",
    "plt.ylabel('Average Orientation deviation')\n",
    "plt.title('Average Orientation deviation vs particles')\n",
    "plt.savefig(path + \"/AveragePhi.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSD_particle(i, positions, box_size, size):\n",
    "    n = np.zeros((size - 1, 2))\n",
    "    result = []\n",
    "    for j in range(math.floor(size - 1.0)):\n",
    "        d = positions[j + 1:, i] - positions[:-j - 1, i]\n",
    "        d -= np.round((d - n) / (box_size)) * box_size\n",
    "        n = d[:-1]\n",
    "        result.append(np.mean((np.linalg.norm(d, axis=1))**2))\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def MSD(particle_data, box_size, time_step, data_compression, skip):\n",
    "    positions = particle_data[::skip, :, :2]\n",
    "    size=positions.shape[0]\n",
    "    num_particles=positions.shape[1]\n",
    "    MSDPerParticle = np.zeros((num_particles, size - 1))\n",
    "\n",
    "    # Create a nested for-loop running through each particle and all possible gap values to create the MSD Matrix\n",
    "    MSDPerParticle=Parallel(n_jobs=-1)(delayed(MSD_particle)(i, positions, box_size, size) for i in tqdm(range(num_particles)))\n",
    "    MSDPerParticle = np.array(MSDPerParticle)\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the MSD values\n",
    "    averageMSDPerGap=[np.mean(MSDPerParticle[:, j]) for j in range(size-1)]\n",
    "    stdMSDPerGap=[np.std(MSDPerParticle[:, j]) for j in range(size-1)]\n",
    "\n",
    "    x=[i*data_compression*time_step*skip for i in range(math.floor(size-1.0))]\n",
    "    y=averageMSDPerGap[:len(x)]\n",
    "    dy=stdMSDPerGap[:len(x)]\n",
    "    return x, y, dy\n",
    "x,y,dy=MSD(particleData, boxSize, timestep, dataCompression, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_MSD(x,y, theta, path):\n",
    "    color = cmap(theta/90)  # Use theta to get a unique color from the colormap\n",
    "    theta_marker = marker_shapes.get(round(theta), 'o')  # Default to circle if theta not in the dictionary\n",
    "    #fit and plot the data with an exponential function and print the fit values\n",
    "    def func(v, a, b, c):\n",
    "        # return a * np.exp(np.array(v)/b) + c\n",
    "        return b * np.array(v) + c\n",
    "    popt, pcov = curve_fit(func, x, y, p0=[1, 100, 0])\n",
    "    # plt.plot(x, func(x, *popt), label=f'Fit:'\" a=\"+str(round(popt[0], 2))+\" b=\"+str(round(popt[1], 2))+\" c=\"+str(round(popt[2], 2)), color=color)\n",
    "    print (popt)\n",
    "    \n",
    "    # plt.plot(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0', marker='o', color=color, markersize=1)\n",
    "    plt.scatter(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0', marker=theta_marker, color=color, s=2)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Time Gap\")\n",
    "    plt.ylabel(\"MSD\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=7)\n",
    "    plt.title(\"Mean Squared Displacement\")\n",
    "    plt.tight_layout()\n",
    "    # Set the figure size (adjust these values as needed)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 6)\n",
    "    plt.savefig(path+\"/MSD.png\", bbox_inches = 'tight')\n",
    "    # return popt and theta as a dictionary for simm plot\n",
    "    return popt\n",
    "\n",
    "plot_MSD(x,y, theta, path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Correlation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoCorrelation_particle(i, positions, box_size, size):\n",
    "    #for each particle i calculate min_image_convention(positions[1:size, i] - positions[0:size-1, i], b)\n",
    "    direction_vector=min_image_convention(positions[1:, i] - positions[0:-1, i], box_size)\n",
    "    dvnorm = np.linalg.norm(direction_vector, axis=1)\n",
    "    direction_vector = direction_vector/dvnorm[:, np.newaxis]\n",
    "    result = []\n",
    "    # Create a nested for-loop running through each particle and gap values\n",
    "    for j in range(size - 1):\n",
    "        result.append(0)\n",
    "        # data[k + 1][i] - data[k][i]\n",
    "        d1 = direction_vector[0:-j-2]\n",
    "        # data[k + j + 2][i] - data[k + j + 1][i]\n",
    "        d2 = direction_vector[j:-2]\n",
    "\n",
    "        dot_product = np.sum(d1 * d2, axis=1)\n",
    "        result[j] = np.sum(dot_product) / (size - j - 1)\n",
    "    return result\n",
    "def autoCorrelation(particle_data, box_size, data_compression, time_step, skip):\n",
    "    # Extracting x and y coordinates from the array\n",
    "    positions = particle_data[::skip, :, :2]\n",
    "    size=positions.shape[0]\n",
    "    num_particles=positions.shape[1]\n",
    "    # Create an empty list to store the \"autoCorrelation list\".\n",
    "    autoCorrelationPerParticle = np.zeros((num_particles, size - 1))\n",
    "\n",
    "    # Create a nested for-loop running through each particle and gap values\n",
    "    autoCorrelationPerParticle = np.zeros((num_particles, size))\n",
    "    autoCorrelationPerParticle=Parallel(n_jobs=-1)(delayed(autoCorrelation_particle)(i, positions, box_size, size) for i in tqdm(range(num_particles)))\n",
    "    autoCorrelationPerParticle = np.array(autoCorrelationPerParticle)\n",
    "    \n",
    "    averageAutoCorrelationPerGap=[np.mean(autoCorrelationPerParticle[:, j]) for j in range(size-1)]\n",
    "    stdAutoCorrelationPerGap=[np.std(autoCorrelationPerParticle[:, j]) for j in range(size-1)]\n",
    "\n",
    "    x=[i*data_compression*time_step*skip for i in range(math.floor(size-2))]\n",
    "    y=averageAutoCorrelationPerGap[:len(x)]\n",
    "    dy=stdAutoCorrelationPerGap[:len(x)]\n",
    "    return x, y, dy\n",
    "\n",
    "x, y, dy=autoCorrelation(particleData, boxSize, dataCompression, timestep, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_AutoCorrelation(x,y, dy, theta, path):\n",
    "    # Calculate the Fourier transform of the autoCorrelation data and Find the peaks in the Fourier transform\n",
    "    fft = np.fft.fft(x)\n",
    "    freq = np.fft.fftfreq(len(x), d=(dataCompression*timestep))\n",
    "    peaks, properties = find_peaks(np.abs(fft), prominence=(10.0, None))\n",
    "    print(2*math.pi/freq[peaks])\n",
    "\n",
    "    # fit the curve with a sinusoidal decaying exponential\n",
    "    def func(p, a, b, c, d):\n",
    "        return  a*np.cos(2*math.pi * (np.array(p)+c)/b)*np.exp(- (np.array(p)+c)/d)\n",
    "    # popt, pcov = curve_fit(func, x, y, p0=[1.0, 100, 1.0,100])\n",
    "\n",
    "    # plt.plot(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0')\n",
    "    plt.errorbar(x,y, yerr=dy, ecolor = 'lightblue', capsize=0, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0')\n",
    "    # plt.plot(x, func (x, *popt), label=f'Fit:'\" a=\"+str(round(popt[0], 2))+\" b=\"+str(round(popt[1], 2))+\" c=\"+str(round(popt[2], 2)), color='red')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Time Gap\")\n",
    "    plt.ylabel(\"autoCorrelation\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=7)\n",
    "\n",
    "    # Set the figure size (adjust these values as needed)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 6)\n",
    "    plt.savefig(path+\"/autoCorrelation.png\", bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_AutoCorrelation(x,y, dy, theta, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence_particle(i, positions, box_size, size):\n",
    "    #for each particle i calculate min_image_convention(positions[1:size, i] - positions[0:size-1, i], b)\n",
    "    direction_vector=min_image_convention(positions[1:, i] - positions[0:-1, i], box_size)\n",
    "    dvnorm = np.linalg.norm(direction_vector, axis=1)\n",
    "    direction_vector = direction_vector/dvnorm[:, np.newaxis]\n",
    "    cosine_matrix = np.dot(direction_vector, direction_vector.T)\n",
    "    result = []\n",
    "    # Create a nested for-loop running through each particle and gap values\n",
    "    for j in range(size):\n",
    "        result.append(0)\n",
    "        for k in range(size - j - 2):\n",
    "            cosines = cosine_matrix[k,k:k+j+1]                 #Broadcasting of numpy arrays is the reason we can do the next step\n",
    "            flag = np.any(cosines < 0)\n",
    "            if not flag: result[j] += 1.0\n",
    "        result[j] = result[j]/ int(size - j)\n",
    "    return result\n",
    "\n",
    "def persistence(particle_data, box_size, data_compression, time_step, skip):\n",
    "    # Extracting x and y coordinates from the array\n",
    "    positions = particle_data[::skip, :, :2]\n",
    "    size=positions.shape[0]\n",
    "    num_particles=positions.shape[1]\n",
    "    \n",
    "    persistencePerParticle = np.zeros((num_particles, size))\n",
    "    persistencePerParticle=Parallel(n_jobs=-1)(delayed(persistence_particle)(i, positions, box_size, size) for i in tqdm(range(num_particles)))\n",
    "    persistencePerParticle = np.array(persistencePerParticle)\n",
    "    # Create a for loop running through persistencePerParticle[i] and finding the mean persistence\n",
    "    averagePersistencePerGap=[np.mean(persistencePerParticle[:, j]) for j in range(size)]\n",
    "\n",
    "    x = [i*data_compression*time_step*skip for i in range(size-1)]\n",
    "    y = averagePersistencePerGap[:len(x)]\n",
    "    \n",
    "    return x, y\n",
    "x, y=persistence(particleData, boxSize, dataCompression, timestep, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_persistence(x, y, theta, save_path):\n",
    "    color = cmap(theta/90)  # Use theta to get a unique color from the colormap\n",
    "    theta_marker = marker_shapes.get(round(theta), 'o')  # Default to circle if theta not in the dictionary\n",
    "    #fit and plot the data with an exponential function and print the fit values\n",
    "    def func(v, a, b, c):\n",
    "        return a * np.exp(-np.array(v)/b) + c\n",
    "    popt, pcov = curve_fit(func, x, y, p0=[1, 100, 0])\n",
    "    # plt.plot(x, func(x, *popt), label=f'Fit:'\" a=\"+str(round(popt[0], 2))+\" b=\"+str(round(popt[1], 2))+\" c=\"+str(round(popt[2], 2)), color=color)\n",
    "    print (popt)\n",
    "\n",
    "    plt.plot(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0', marker=theta_marker, color=color, markersize=2)\n",
    "    # plt.scatter(x, y, label=f'Vission Angle \\u03B8={round(theta)}\\u00B0', marker=theta_marker, color=color, s=2)\n",
    "    \n",
    "    # plt.xscale('log')\n",
    "    # plt.yscale('log', base=2)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Time Gap\")\n",
    "    plt.ylabel(\"Persistence\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=7)\n",
    "    # Set the figure size (adjust these values as needed)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 6)\n",
    "    plt.savefig(save_path+\"/persistence.png\", bbox_inches = 'tight')\n",
    "    return popt\n",
    "plot_persistence(x, y, theta, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence(datain):\n",
    "    data=datain\n",
    "    size=particleData.shape[0]\n",
    "    # Create an empty list to store the \"Persistence list\" and  average persistence per gap\n",
    "    persistencePerParticle = [[0.0] * (size) for i in range(numParticles)]\n",
    "    averagePersistencePerGap = [0.0] * (size)\n",
    "    # Create a nested for-loop running through each particle all the possible gap values to create the Persistence Matrix; here j will be called \"gap\"\n",
    "    for i in tqdm(range(numParticles)):\n",
    "        for j in range(size):\n",
    "            for k in range(size - j - 1):  # -1 because we want to avoid the last particle as there is no k+1 for it\n",
    "                flag = 0\n",
    "                d1x = min_image_convention(data[k + 1][i][0] - data[k][i][0], boxSize)\n",
    "                d1y = min_image_convention(data[k + 1][i][1] - data[k][i][1], boxSize)\n",
    "                d1norm = math.sqrt(d1x**2 + d1y**2)\n",
    "                for l in range(j + 1):\n",
    "                    d2x = min_image_convention(data[k + l + 1][i][0] - data[k + l][i][0], boxSize)\n",
    "                    d2y = min_image_convention(data[k + l + 1][i][1] - data[k + l][i][1], boxSize)\n",
    "                    d2norm = math.sqrt(d2x**2 + d2y**2)\n",
    "                    if (d1x * d2x + d1y * d2y) / (d1norm * d2norm) < 0:  # if cos becomes negative\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    persistencePerParticle[i][j] += 1.0\n",
    "\n",
    "            persistencePerParticle[i][j] /= int(size - j)\n",
    "\n",
    "    # Create a for loop running through persistencePerParticle[i] and finding the mean persistence\n",
    "    for j in tqdm(range(size)):\n",
    "        persistenceValues = []\n",
    "        for i in range(numParticles):\n",
    "            # Add the persistence of each particle at a given gap to the list\n",
    "            persistenceValues.append(persistencePerParticle[i][j])\n",
    "\n",
    "        # Calculate the mean  of the persistence values\n",
    "        averagePersistencePerGap[j] = np.mean(persistenceValues)\n",
    "\n",
    "    x = [i*dataCompression*timestep for i in range(size-1)]\n",
    "    y = averagePersistencePerGap[:len(x)]\n",
    "    \n",
    "    return y, x\n",
    "x, y=persistence(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simultaneous Averaging Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = r\"Runs\\High Density\\CRun\" \n",
    "file_paths = [f.path+\"/\" for f in os.scandir(parent_folder) if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simPlot(file_paths):\n",
    "    Plot_Data={}\n",
    "    No_of_Runs_per_theta={}\n",
    "    for file_path in tqdm(file_paths):\n",
    "        data = load_data(file_path)\n",
    "        particle_data = np.array(data)\n",
    "        \n",
    "        variable_dict=save_param(file_path)\n",
    "        theta=(float(variable_dict[\"theta\"]))\n",
    "        boxSize=float(variable_dict[\"boxSize\"])\n",
    "        timestep=float(variable_dict[\"timestep\"])\n",
    "        dataCompression=int(variable_dict[\"dataCompression\"])\n",
    "        \n",
    "        # a = np.array(MSD(particle_data[::5], boxSize, timestep, dataCompression, 1))\n",
    "        a = np.array(persistence(particle_data, boxSize, dataCompression, timestep, 5))\n",
    "\n",
    "        if theta not in Plot_Data:\n",
    "            Plot_Data[theta] = a\n",
    "            No_of_Runs_per_theta[theta] = 1\n",
    "        else:\n",
    "            Plot_Data[theta][1] += a[1]\n",
    "            No_of_Runs_per_theta[theta] += 1\n",
    "    print (No_of_Runs_per_theta)\n",
    "\n",
    "    for theta in Plot_Data: Plot_Data[theta][1] /= No_of_Runs_per_theta[theta]\n",
    "    return Plot_Data\n",
    "l=simPlot(file_paths)\n",
    "l = dict(sorted(l.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_values={}\n",
    "for theta in l:\n",
    "        popt=plot_persistence(l[theta][0], l[theta][1], theta, parent_folder)\n",
    "        # popt = plot_MSD(l[theta][0], l[theta][1], theta, parent_folder)\n",
    "        fit_values[theta]=popt\n",
    "# Save to Excel\n",
    "df = pd.DataFrame.from_dict(fit_values, orient='index')\n",
    "# df.to_excel(parent_folder+\"/fit_valuesMSD.xlsx\")\n",
    "df.to_excel(parent_folder+\"/fit_valuesPersistence.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from Excel and save it as a dictionary\n",
    "df = pd.read_excel(parent_folder+\"/fit_valuesPersistence.xlsx\")\n",
    "fit_values = df.set_index('Unnamed: 0').T.to_dict('list')\n",
    "#plot the fit values\n",
    "plt.plot(list(fit_values.keys()), [i[1] for i in list(fit_values.values())], label='b', marker=\"s\", markersize=2)\n",
    "plt.xlabel(\"Vission Angle\")\n",
    "plt.ylabel(\"Fit Values\")\n",
    "plt.legend()\n",
    "plt.savefig(parent_folder+\"/Persistencefit_values.png\")\n",
    "# plt.savefig(parent_folder+\"/MSDfit_values.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simGif():\n",
    "    parent_folder = r\"Runs\\High Density\\CRun\" \n",
    "    file_paths = [f.path+\"/\" for f in os.scandir(parent_folder) if f.is_dir()]\n",
    "    for file_path in tqdm(file_paths):\n",
    "        data = load_data(file_path)\n",
    "        particleData = np.array(data)\n",
    "        \n",
    "        variable_dict=save_param(file_path)\n",
    "        theta=(float(variable_dict[\"theta\"]))\n",
    "        boxSize=float(variable_dict[\"boxSize\"])\n",
    "        timestep=float(variable_dict[\"timestep\"])\n",
    "        dataCompression=int(variable_dict[\"dataCompression\"])\n",
    "        animator(particleData, boxSize, file_path, 5)\n",
    "simGif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simAutoC():\n",
    "    parent_folder = r\"Runs\\High Density\\CRun\" \n",
    "    file_paths = [f.path+\"/\" for f in os.scandir(parent_folder) if f.is_dir()]\n",
    "    for file_path in tqdm(file_paths):\n",
    "        data = load_data(file_path)\n",
    "        particleData = np.array(data)\n",
    "        \n",
    "        variable_dict=save_param(file_path)\n",
    "        theta=(float(variable_dict[\"theta\"]))\n",
    "        boxSize=float(variable_dict[\"boxSize\"])\n",
    "        timestep=float(variable_dict[\"timestep\"])\n",
    "        dataCompression=int(variable_dict[\"dataCompression\"])\n",
    "        out=autoCorrelation(particleData, boxSize, dataCompression, timestep, 5)\n",
    "        plot_AutoCorrelation(out[0],out[1], out[2], theta, file_path)\n",
    "        \n",
    "simAutoC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run(\"persistence(data)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
